{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c70f67-7997-41ec-bd84-484a01a9ac83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from stress_detection_model.h5\n",
      "Starting Enhanced Classroom Stress Detection System v2.0\n",
      "Attempting to connect to: rtsp://DYPDPU:Admin@123@10.10.122.187:554/Streaming/Channels/101\n",
      "Connected to rtsp://DYPDPU:Admin@123@10.10.122.187:554/Streaming/Channels/101\n",
      "Camera resolution: 2560.0x1440.0\n",
      "Initializing camera stream...\n",
      "Stopping application...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import threading\n",
    "\n",
    "# Configuration\n",
    "CAMERA_CONFIG = {\n",
    "    \"ip_address\": \"\",  # ADD IP ADDRESS OF YOUR CAMERA\n",
    "    \"username\": \"\",     # ADD USERNAME OF YOUR CAMERA\n",
    "    \"password\": \"\",    # ADD PASSWORD OF YOUR CAMERA\n",
    "    \"port\": 554\n",
    "}\n",
    "MODEL_PATH = \"stress_detection_model.h5\"\n",
    "IMG_SIZE = 48\n",
    "MIN_FACE_SIZE = 30  # Increased minimum face size to reduce false positives\n",
    "CONFIDENCE_THRESHOLD = 0.7  # Increased confidence threshold\n",
    "TRACK_PERSISTENCE = 30  # Number of frames to keep tracking a face after loss\n",
    "DETECTION_INTERVAL = 5  # Process detection every N frames for stability\n",
    "\n",
    "# Use GPU if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize face detector with stricter parameters\n",
    "from facenet_pytorch import MTCNN\n",
    "detector = MTCNN(\n",
    "    keep_all=True,\n",
    "    min_face_size=MIN_FACE_SIZE,\n",
    "    thresholds=[0.6, 0.7, 0.9],  # Increased thresholds to reduce false positives\n",
    "    post_process=True,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Load stress detection model with error handling\n",
    "try:\n",
    "    model = load_model(MODEL_PATH)\n",
    "    print(f\"Model loaded successfully from {MODEL_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    model = None\n",
    "\n",
    "class CCTVStream:\n",
    "    def __init__(self):\n",
    "        self.cap = self._connect_camera()\n",
    "        self.frame = None\n",
    "        self.running = True\n",
    "        self.reconnect_attempts = 0\n",
    "        self.frame_size = None\n",
    "        \n",
    "    def _connect_camera(self):\n",
    "        rtsp_paths = [\n",
    "            \"/Streaming/Channels/101\",\n",
    "            \"/Streaming/Channels/102\",\n",
    "            \"/live\",\n",
    "            \"/h264\",\n",
    "            \"/cam/realmonitor?channel=1&subtype=0\"\n",
    "        ]\n",
    "        \n",
    "        for path in rtsp_paths:\n",
    "            url = f\"rtsp://{CAMERA_CONFIG['username']}:{CAMERA_CONFIG['password']}@\" \\\n",
    "                  f\"{CAMERA_CONFIG['ip_address']}:{CAMERA_CONFIG['port']}{path}\"\n",
    "            print(f\"Attempting to connect to: {url}\")\n",
    "            cap = cv2.VideoCapture(url)\n",
    "            \n",
    "            # Check if connection is successful\n",
    "            if cap.isOpened():\n",
    "                # Set buffer size to minimize latency\n",
    "                cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "                \n",
    "                # Try to set higher resolution\n",
    "                cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "                \n",
    "                # Check if resolution was accepted\n",
    "                width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "                height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "                self.frame_size = (int(width), int(height))\n",
    "                \n",
    "                print(f\"Connected to {url}\")\n",
    "                print(f\"Camera resolution: {width}x{height}\")\n",
    "                return cap\n",
    "                \n",
    "            cap.release()\n",
    "        \n",
    "        print(\"Using fallback webcam\")\n",
    "        cap = cv2.VideoCapture(0)  # Use built-in webcam as fallback\n",
    "        \n",
    "        # Set resolution for webcam\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "        \n",
    "        width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "        height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "        self.frame_size = (int(width), int(height))\n",
    "        print(f\"Webcam resolution: {width}x{height}\")\n",
    "        \n",
    "        return cap\n",
    "        \n",
    "    def start(self):\n",
    "        while self.running:\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                # Ensure frame is properly oriented\n",
    "                # Uncomment and adjust if your camera feed is flipped or rotated\n",
    "                # frame = cv2.flip(frame, 1)  # 1 for horizontal flip\n",
    "                \n",
    "                # Check if we need to resize for display purposes\n",
    "                if self.frame_size and (frame.shape[1] != self.frame_size[0] or \n",
    "                                        frame.shape[0] != self.frame_size[1]):\n",
    "                    frame = cv2.resize(frame, self.frame_size)\n",
    "                    \n",
    "                self.frame = frame\n",
    "                self.reconnect_attempts = 0\n",
    "            else:\n",
    "                print(f\"Failed to read frame, attempt {self.reconnect_attempts + 1}\")\n",
    "                self.reconnect_attempts += 1\n",
    "                \n",
    "                if self.reconnect_attempts > 5:\n",
    "                    print(\"Reconnecting to camera...\")\n",
    "                    self.cap.release()\n",
    "                    self.cap = self._connect_camera()\n",
    "                    self.reconnect_attempts = 0\n",
    "                    \n",
    "                time.sleep(1)\n",
    "    \n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "\n",
    "def validate_face(face_roi):\n",
    "    \"\"\"Advanced face validation with stricter checks to filter out false positives\"\"\"\n",
    "    # Check if face_roi is valid\n",
    "    if face_roi is None or face_roi.size == 0 or face_roi.shape[0] < 20 or face_roi.shape[1] < 20:\n",
    "        return False\n",
    "    \n",
    "    # 1. Texture analysis with higher threshold to ensure it's a real face\n",
    "    try:\n",
    "        gray = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "        texture_score = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "        if texture_score < 50:  # Increased from 25 for better filtering\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error in texture analysis: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # 2. Improved color consistency check for faces\n",
    "    try:\n",
    "        hsv = cv2.cvtColor(face_roi, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Multiple skin tone ranges (more inclusive)\n",
    "        # Light skin\n",
    "        skin_lower1 = np.array([0, 15, 60], dtype=np.uint8)\n",
    "        skin_upper1 = np.array([25, 255, 255], dtype=np.uint8)\n",
    "        mask1 = cv2.inRange(hsv, skin_lower1, skin_upper1)\n",
    "        \n",
    "        # Darker skin\n",
    "        skin_lower2 = np.array([0, 10, 40], dtype=np.uint8)\n",
    "        skin_upper2 = np.array([30, 255, 200], dtype=np.uint8)\n",
    "        mask2 = cv2.inRange(hsv, skin_lower2, skin_upper2)\n",
    "        \n",
    "        # Combine masks\n",
    "        skin_mask = cv2.bitwise_or(mask1, mask2)\n",
    "        skin_ratio = cv2.countNonZero(skin_mask) / (face_roi.size / 3)\n",
    "        \n",
    "        if skin_ratio < 0.25:  # Increased from 0.15 to be more strict\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error in color check: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # 3. Check for eye-like regions (basic structural check)\n",
    "    try:\n",
    "        # Use Haar cascade to detect eyes\n",
    "        eyes_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "        eyes = eyes_cascade.detectMultiScale(gray, 1.1, 3)\n",
    "        if len(eyes) < 1:  # At least one eye should be visible in a valid face\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        # If error occurs, don't fail the validation\n",
    "        pass\n",
    "    \n",
    "    return True\n",
    "\n",
    "def process_frame(frame, detector):\n",
    "    \"\"\"Process a frame to detect faces using MTCNN with improved parameters\"\"\"\n",
    "    if frame is None:\n",
    "        print(\"Empty frame received\")\n",
    "        return []\n",
    "    \n",
    "    height, width = frame.shape[:2]\n",
    "    \n",
    "    # Convert to RGB for MTCNN\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    try:\n",
    "        # Use batch_size=1 for real-time processing\n",
    "        boxes, probs = detector.detect(rgb_frame, landmarks=False)\n",
    "        \n",
    "        valid_faces = []\n",
    "        if boxes is not None:\n",
    "            for box, confidence in zip(boxes, probs):\n",
    "                if confidence < 0.70:  # Increased confidence threshold\n",
    "                    continue\n",
    "                    \n",
    "                x1, y1, x2, y2 = [int(b) for b in box]\n",
    "                \n",
    "                # Ensure face is within boundaries\n",
    "                x1 = max(0, x1)\n",
    "                y1 = max(0, y1)\n",
    "                x2 = min(width, x2)\n",
    "                y2 = min(height, y2)\n",
    "                \n",
    "                w = x2 - x1\n",
    "                h = y2 - y1\n",
    "                \n",
    "                # Skip very small faces\n",
    "                if w < MIN_FACE_SIZE or h < MIN_FACE_SIZE:\n",
    "                    continue\n",
    "                \n",
    "                # Enlarge detection area slightly for better stress analysis\n",
    "                padding = int(max(w, h) * 0.1)  # 10% padding\n",
    "                x1 = max(0, x1 - padding)\n",
    "                y1 = max(0, y1 - padding)\n",
    "                x2 = min(width, x2 + padding)\n",
    "                y2 = min(height, y2 + padding)\n",
    "                \n",
    "                w = x2 - x1\n",
    "                h = y2 - y1\n",
    "                \n",
    "                face_roi = frame[y1:y2, x1:x2]\n",
    "                \n",
    "                # Validate face using our additional checks\n",
    "                if validate_face(face_roi):\n",
    "                    valid_faces.append((x1, y1, w, h))\n",
    "        \n",
    "        return valid_faces\n",
    "    except Exception as e:\n",
    "        print(f\"Error in face detection: {e}\")\n",
    "        return []\n",
    "\n",
    "def predict_stress(face_roi):\n",
    "    \"\"\"Predict stress with histogram equalization for better feature detection\"\"\"\n",
    "    if face_roi is None or face_roi.size == 0 or model is None:\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        # Preprocess image for the model\n",
    "        gray = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply adaptive histogram equalization to improve feature visibility\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        equalized = clahe.apply(gray)\n",
    "        \n",
    "        # Resize to model input size\n",
    "        resized = cv2.resize(equalized, (IMG_SIZE, IMG_SIZE))\n",
    "        normalized = resized / 255.0\n",
    "        input_tensor = np.expand_dims(normalized, axis=(0, -1))\n",
    "        \n",
    "        # Make prediction\n",
    "        preds = model.predict(input_tensor, verbose=0)[0]\n",
    "        emotion_idx = np.argmax(preds)\n",
    "        confidence = preds[emotion_idx]\n",
    "        \n",
    "        if confidence < CONFIDENCE_THRESHOLD:\n",
    "            return None, None\n",
    "        \n",
    "        # Stress mapping - use based on your specific model's classes\n",
    "        stress_labels = {\n",
    "            0: \"Stressed\",    # Angry\n",
    "            1: \"Stressed\",    # Disgust\n",
    "            2: \"Stressed\",    # Fear\n",
    "            3: \"Not Stressed\", # Happy\n",
    "            4: \"Not Stressed\", # Neutral\n",
    "            5: \"Stressed\",     # Sad\n",
    "            6: \"Not Stressed\"  # Surprise\n",
    "        }\n",
    "        \n",
    "        return stress_labels[emotion_idx], confidence\n",
    "    except Exception as e:\n",
    "        print(f\"Error in stress prediction: {e}\")\n",
    "        return None, None\n",
    "\n",
    "class FaceTracker:\n",
    "    \"\"\"Enhanced face tracker with persistence and stability features\"\"\"\n",
    "    def __init__(self, max_disappeared=TRACK_PERSISTENCE):\n",
    "        # Structure: {ID: {\n",
    "        #   'bbox': (x, y, w, h),\n",
    "        #   'disappeared': counter,\n",
    "        #   'history': list of last positions,\n",
    "        #   'stress_history': list of last stress readings,\n",
    "        #   'stress_status': current stress status,\n",
    "        #   'confidence': confidence in stress reading,\n",
    "        #   'stable_count': count of consistent readings\n",
    "        # }}\n",
    "        self.faces = {}\n",
    "        self.next_id = 0\n",
    "        self.max_disappeared = max_disappeared\n",
    "        self.max_history = 10  # Keep last 10 positions for trajectory\n",
    "    \n",
    "    def register(self, bbox):\n",
    "        \"\"\"Register a new face\"\"\"\n",
    "        self.faces[self.next_id] = {\n",
    "            'bbox': bbox,\n",
    "            'disappeared': 0,\n",
    "            'history': [bbox],\n",
    "            'stress_history': [],\n",
    "            'stress_status': None,\n",
    "            'confidence': 0.0,\n",
    "            'stable_count': 0\n",
    "        }\n",
    "        face_id = self.next_id\n",
    "        self.next_id += 1\n",
    "        return face_id\n",
    "    \n",
    "    def deregister(self, face_id):\n",
    "        \"\"\"Remove a face from tracking\"\"\"\n",
    "        if face_id in self.faces:\n",
    "            del self.faces[face_id]\n",
    "    \n",
    "    def update(self, rects):\n",
    "        \"\"\"Update tracker with new detections\"\"\"\n",
    "        # If no faces were detected\n",
    "        if len(rects) == 0:\n",
    "            # Mark all faces as disappeared\n",
    "            for face_id in list(self.faces.keys()):\n",
    "                self.faces[face_id]['disappeared'] += 1\n",
    "                \n",
    "                # Deregister if a face has been missing too long\n",
    "                if self.faces[face_id]['disappeared'] > self.max_disappeared:\n",
    "                    self.deregister(face_id)\n",
    "            \n",
    "            return self.faces\n",
    "        \n",
    "        # Initialize array of input centroids\n",
    "        input_centroids = np.zeros((len(rects), 2), dtype=\"float\")\n",
    "        input_bboxes = []\n",
    "        \n",
    "        # Calculate centroids\n",
    "        for (i, (x, y, w, h)) in enumerate(rects):\n",
    "            cx = x + w // 2\n",
    "            cy = y + h // 2\n",
    "            input_centroids[i] = (cx, cy)\n",
    "            input_bboxes.append((x, y, w, h))\n",
    "        \n",
    "        # If no faces are being tracked, register all\n",
    "        if len(self.faces) == 0:\n",
    "            for i in range(len(input_bboxes)):\n",
    "                self.register(input_bboxes[i])\n",
    "        \n",
    "        # Otherwise match input centroids to existing face centroids\n",
    "        else:\n",
    "            face_ids = list(self.faces.keys())\n",
    "            face_centroids = []\n",
    "            \n",
    "            # Get centroids of current tracked faces\n",
    "            for face_id in face_ids:\n",
    "                x, y, w, h = self.faces[face_id]['bbox']\n",
    "                face_centroids.append((x + w // 2, y + h // 2))\n",
    "            \n",
    "            face_centroids = np.array(face_centroids)\n",
    "            \n",
    "            # Compute distances between each pair of centroids\n",
    "            D = np.zeros((len(face_centroids), len(input_centroids)))\n",
    "            for i in range(len(face_centroids)):\n",
    "                for j in range(len(input_centroids)):\n",
    "                    # Calculate Euclidean distance\n",
    "                    D[i, j] = np.linalg.norm(face_centroids[i] - input_centroids[j])\n",
    "            \n",
    "            # Find the smallest value in each row and column\n",
    "            rows = D.min(axis=1).argsort()\n",
    "            cols = np.zeros(len(rows), dtype=int)\n",
    "            used_cols = set()\n",
    "            \n",
    "            # Loop over rows sorted by min distance\n",
    "            for row in rows:\n",
    "                # Sort columns for this row\n",
    "                row_cols = D[row].argsort()\n",
    "                \n",
    "                # Find the smallest available column\n",
    "                for col in row_cols:\n",
    "                    if col not in used_cols:\n",
    "                        cols[row] = col\n",
    "                        used_cols.add(col)\n",
    "                        break\n",
    "            \n",
    "            # Check for unused row/column indices\n",
    "            unused_rows = set(range(len(face_centroids))) - set(rows)\n",
    "            unused_cols = set(range(len(input_centroids))) - used_cols\n",
    "            \n",
    "            # Compute maximum acceptable distance for matching\n",
    "            # This dynamically adjusts based on average face size\n",
    "            if len(self.faces) > 0:\n",
    "                avg_size = np.mean([max(face['bbox'][2], face['bbox'][3]) for face in self.faces.values()])\n",
    "                max_distance = avg_size * 0.5  # Half the avg face size for matching threshold\n",
    "            else:\n",
    "                max_distance = 50  # Default value\n",
    "            \n",
    "            # Check if matched centroids are close enough\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                if D[row, col] > max_distance:\n",
    "                    unused_rows.add(row)\n",
    "                    unused_cols.add(col)\n",
    "            \n",
    "            # Update matched faces\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                if row not in unused_rows and col not in used_cols:\n",
    "                    face_id = face_ids[row]\n",
    "                    \n",
    "                    # Get current face data\n",
    "                    face = self.faces[face_id]\n",
    "                    new_bbox = input_bboxes[col]\n",
    "                    \n",
    "                    # Update with new position\n",
    "                    face['bbox'] = new_bbox\n",
    "                    face['disappeared'] = 0\n",
    "                    \n",
    "                    # Add to position history\n",
    "                    face['history'].append(new_bbox)\n",
    "                    if len(face['history']) > self.max_history:\n",
    "                        face['history'] = face['history'][-self.max_history:]\n",
    "            \n",
    "            # Register new faces\n",
    "            for col in unused_cols:\n",
    "                self.register(input_bboxes[col])\n",
    "            \n",
    "            # Mark unmatched faces as disappeared\n",
    "            for row in unused_rows:\n",
    "                face_id = face_ids[row]\n",
    "                self.faces[face_id]['disappeared'] += 1\n",
    "                \n",
    "                # Predict new position based on history\n",
    "                if len(self.faces[face_id]['history']) >= 2:\n",
    "                    # Get last two positions\n",
    "                    last = self.faces[face_id]['history'][-1]\n",
    "                    prev = self.faces[face_id]['history'][-2]\n",
    "                    \n",
    "                    # Calculate velocity (movement vector)\n",
    "                    vx = last[0] - prev[0]\n",
    "                    vy = last[1] - prev[1]\n",
    "                    \n",
    "                    # Apply velocity to predict new position\n",
    "                    x, y, w, h = last\n",
    "                    new_x = int(x + vx * 0.8)  # Dampen movement for stability\n",
    "                    new_y = int(y + vy * 0.8)\n",
    "                    \n",
    "                    # Update bbox with prediction\n",
    "                    self.faces[face_id]['bbox'] = (new_x, new_y, w, h)\n",
    "                \n",
    "                # Deregister if a face has been missing too long\n",
    "                if self.faces[face_id]['disappeared'] > self.max_disappeared:\n",
    "                    self.deregister(face_id)\n",
    "        \n",
    "        return self.faces\n",
    "    \n",
    "    def update_stress(self, face_id, stress_status, confidence):\n",
    "        \"\"\"Update stress status for a tracked face\"\"\"\n",
    "        if face_id in self.faces:\n",
    "            if stress_status is not None:\n",
    "                self.faces[face_id]['stress_history'].append(stress_status)\n",
    "                # Keep last 5 stress readings\n",
    "                if len(self.faces[face_id]['stress_history']) > 5:\n",
    "                    self.faces[face_id]['stress_history'] = self.faces[face_id]['stress_history'][-5:]\n",
    "                \n",
    "                # Get most common stress status\n",
    "                if len(self.faces[face_id]['stress_history']) >= 3:\n",
    "                    # Count occurrences\n",
    "                    status_count = {}\n",
    "                    for status in self.faces[face_id]['stress_history']:\n",
    "                        if status not in status_count:\n",
    "                            status_count[status] = 0\n",
    "                        status_count[status] += 1\n",
    "                    \n",
    "                    # Get most common status\n",
    "                    most_common = max(status_count, key=status_count.get)\n",
    "                    count = status_count[most_common]\n",
    "                    \n",
    "                    # Update if the count is over half of all readings\n",
    "                    if count >= len(self.faces[face_id]['stress_history']) / 2:\n",
    "                        # If same as current, increase stability counter\n",
    "                        if self.faces[face_id]['stress_status'] == most_common:\n",
    "                            self.faces[face_id]['stable_count'] += 1\n",
    "                        else:\n",
    "                            # New status, reset stability\n",
    "                            self.faces[face_id]['stress_status'] = most_common\n",
    "                            self.faces[face_id]['stable_count'] = 1\n",
    "                        \n",
    "                        self.faces[face_id]['confidence'] = confidence\n",
    "                \n",
    "                # Initial status\n",
    "                elif self.faces[face_id]['stress_status'] is None:\n",
    "                    self.faces[face_id]['stress_status'] = stress_status\n",
    "                    self.faces[face_id]['confidence'] = confidence\n",
    "                    self.faces[face_id]['stable_count'] = 1\n",
    "            \n",
    "            return self.faces[face_id]['stress_status'], self.faces[face_id]['confidence']\n",
    "        \n",
    "        return None, None\n",
    "\n",
    "def main():\n",
    "    print(\"Starting Enhanced Classroom Stress Detection System v2.0\")\n",
    "    \n",
    "    # Verify model exists\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        print(f\"ERROR: Model file not found at {MODEL_PATH}\")\n",
    "        print(\"Please check the file path and ensure the model exists\")\n",
    "        return\n",
    "        \n",
    "    # Create output directory\n",
    "    os.makedirs(\"stress_logs\", exist_ok=True)\n",
    "    \n",
    "    # Initialize camera stream\n",
    "    stream = CCTVStream()\n",
    "    stream_thread = threading.Thread(target=stream.start)\n",
    "    stream_thread.daemon = True\n",
    "    stream_thread.start()\n",
    "    \n",
    "    # Allow camera to initialize\n",
    "    print(\"Initializing camera stream...\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Initialize improved face tracker\n",
    "    face_tracker = FaceTracker(max_disappeared=TRACK_PERSISTENCE)\n",
    "    \n",
    "    # Tracking variables\n",
    "    fps_counter = 0\n",
    "    fps = 0\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "    last_detection_frame = 0\n",
    "    \n",
    "    # Create window with adjusted properties\n",
    "    cv2.namedWindow(\"Classroom Stress Monitor\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"Classroom Stress Monitor\", 1280, 720)\n",
    "    \n",
    "    # Create history buffer for people count stability\n",
    "    people_count_history = []\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            if stream.frame is None:\n",
    "                print(\"Waiting for valid frame...\")\n",
    "                time.sleep(0.5)\n",
    "                continue\n",
    "            \n",
    "            frame = stream.frame.copy()\n",
    "            frame_count += 1\n",
    "            \n",
    "            # Run face detection at fixed intervals for stability\n",
    "            faces = []\n",
    "            if frame_count - last_detection_frame >= DETECTION_INTERVAL:\n",
    "                faces = process_frame(frame, detector)\n",
    "                last_detection_frame = frame_count\n",
    "                \n",
    "                # Update people count history (for smoothing)\n",
    "                people_count_history.append(len(faces))\n",
    "                if len(people_count_history) > 10:\n",
    "                    people_count_history = people_count_history[-10:]\n",
    "            \n",
    "            # Update tracker with detected faces\n",
    "            active_faces = face_tracker.update(faces)\n",
    "            \n",
    "            # Calculate a stable people count (median of recent history)\n",
    "            stable_count = np.median(people_count_history) if people_count_history else 0\n",
    "            \n",
    "            # Process each tracked face\n",
    "            for face_id, face_data in active_faces.items():\n",
    "                x, y, w, h = face_data['bbox']\n",
    "                \n",
    "                # Convert to integers and ensure within frame boundaries\n",
    "                x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "                if x < 0: x = 0\n",
    "                if y < 0: y = 0\n",
    "                if x + w > frame.shape[1]: w = frame.shape[1] - x\n",
    "                if y + h > frame.shape[0]: h = frame.shape[0] - y\n",
    "                \n",
    "                # Skip if dimensions are invalid\n",
    "                if w <= 0 or h <= 0 or x + w > frame.shape[1] or y + h > frame.shape[0]:\n",
    "                    continue\n",
    "                \n",
    "                face_roi = frame[y:y+h, x:x+w]\n",
    "                \n",
    "                # Process stress detection only on frames where we run detection\n",
    "                # or if face doesn't have stress status yet\n",
    "                if frame_count - last_detection_frame < 3 or face_data['stress_status'] is None:\n",
    "                    stress, confidence = predict_stress(face_roi)\n",
    "                    face_tracker.update_stress(face_id, stress, confidence)\n",
    "                \n",
    "                # Get current stress status\n",
    "                stress = face_data['stress_status']\n",
    "                confidence = face_data['confidence']\n",
    "                stable_count = face_data['stable_count']\n",
    "                \n",
    "                # Draw results with improved visualization\n",
    "                if stress is not None:\n",
    "                    # Set color based on stress status\n",
    "                    color = (0, 0, 255) if stress == \"Stressed\" else (0, 255, 0)\n",
    "                    \n",
    "                    # Use thicker lines for more stable detections\n",
    "                    thickness = min(1 + (stable_count // 3), 4)\n",
    "                    \n",
    "                    # Draw face box with rounded corners\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), color, thickness)\n",
    "                    \n",
    "                    # Create transparent overlay for better visibility\n",
    "                    overlay = frame.copy()\n",
    "                    alpha = 0.3  # Transparency factor\n",
    "                    \n",
    "                    # Draw semi-transparent colored rectangle\n",
    "                    cv2.rectangle(overlay, (x, y-30), (x+w, y), color, -1)\n",
    "                    cv2.addWeighted(overlay, alpha, frame, 1-alpha, 0, frame)\n",
    "                    \n",
    "                    # Add text with better visibility\n",
    "                    stability_indicator = \"â—\" * min(stable_count, 5)  # Show up to 5 dots for stability\n",
    "                    label = f\"{stress} {stability_indicator}\"\n",
    "                    cv2.putText(frame, label, (x+5, y-10), \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                    \n",
    "                    # Add face ID for debugging\n",
    "                    cv2.putText(frame, f\"ID:{face_id}\", (x+5, y+h-10),\n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "                    \n",
    "                    # Log stressed students with improved quality\n",
    "                    if stress == \"Stressed\" and confidence > 0.75 and frame_count % 50 == 0:\n",
    "                        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                        # Save both face and context\n",
    "                        cv2.imwrite(f\"stress_logs/stressed_face_{face_id}_{timestamp}.jpg\", face_roi)\n",
    "                        \n",
    "                        # Save context with highlighted face\n",
    "                        context = frame.copy()\n",
    "                        cv2.rectangle(context, (x, y), (x+w, y+h), (0, 0, 255), 3)\n",
    "                        cv2.imwrite(f\"stress_logs/stressed_context_{face_id}_{timestamp}.jpg\", context)\n",
    "            \n",
    "            # Calculate FPS with smoother averaging\n",
    "            fps_counter += 1\n",
    "            if time.time() - start_time >= 1:\n",
    "                fps = fps_counter\n",
    "                fps_counter = 0\n",
    "                start_time = time.time()\n",
    "            \n",
    "            # Create transparent overlay for debug info\n",
    "            overlay = frame.copy()\n",
    "            cv2.rectangle(overlay, (5, 5), (300, 110), (0, 0, 0), -1)\n",
    "            cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)\n",
    "            \n",
    "            # Display debug info with better formatting\n",
    "            cv2.putText(frame, f\"FPS: {fps}\", (10, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            cv2.putText(frame, f\"Active People: {len(active_faces)}\", (10, 60), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            cv2.putText(frame, f\"Stable Count: {int(stable_count)}\", (10, 90), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            \n",
    "            # Display controls information\n",
    "            cv2.putText(frame, \"Press 'q' to quit, 'f' for fullscreen\", (frame.shape[1]-400, 30),\n",
    "                      cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "            \n",
    "            # Show frame in resizable window\n",
    "            cv2.imshow(\"Classroom Stress Monitor\", frame)\n",
    "            \n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('f'):  # Toggle fullscreen\n",
    "                if cv2.getWindowProperty(\"Classroom Stress Monitor\", cv2.WND_PROP_FULLSCREEN) == 0:\n",
    "                    cv2.setWindowProperty(\"Classroom Stress Monitor\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "                else:\n",
    "                    cv2.setWindowProperty(\"Classroom Stress Monitor\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_NORMAL)\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopping application...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main loop: {e}\")\n",
    "    finally:\n",
    "        stream.stop()\n",
    "        stream_thread.join(timeout=1.0)\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Application closed\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (Insight)",
   "language": "python",
   "name": "insightenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
